\documentclass[11pt]{article}
\usepackage{color, array, graphics}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{mathtools}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}

%Symbol shortcuts
\def\OR{\vee}
\def\AND{\wedge}
\def\imp{\rightarrow}


\begin{document}

\begin{center} Alexander Garcia \hfill June 5, 2017 \\ Assignment-2 \end{center}

\medskip

\begin{enumerate}

\item

	\begin{enumerate}[(a)]

		\item Consider the functions $f(x) = x^3 - 2,\ g(x) = e^x - 5sin(x^3) - 3cos(x)$. \\

		The initial step in the bisection process is to choose a range of $x$ in which $f(x) = 0$. As the range is given to be $(0,2)$,
		the bisection algorithm proceeds by guessing the midpoint of the range (let's call this $x_0 = \frac{b_0-a_0}{2}$) to be a zero
		of the function. If $|f(x_0)| \leq 0 + tol$, then the zero is said to have been found. If $|f(x_0)| > 0 + tol$, then either
		$a_0$ or $b_0$ is replaced by $x_0$, depending on where $f(x)$ changes sign. The process is then repeated until
		$f(x_n) < 0 + tol$. \\

		At each stage in the algorithm, the maximum possible error of $f(x_n)$ is $e_n = \frac{b_n-a_n}{2}$, and the general error is
		$e_n \leq \frac{b_n-a_n}{2}$. Because $b_n-a_n = \frac{b_{n-1}-a_{n-1}}{2}$, we can express the current error as
		$$e_n \leq \frac{1}{2} e_{n-1}$$

		In this case we are taking 34 iterations until $e_n$ is reasonably low, so $e_{34} = \frac{1}{2} e_{33}$. It is clear that this
		expression will cascade down to $e_0$, the error of the initial guess. The final error $e_{34}$ can therefore be generalized
		to
		$$e_0*\prod_{i = 1}^{34}\frac{1}{2} = 1*\prod_{i=1}^{34}\frac{1}{2} = \frac{1}{2^{34}} $$

		This result shows that the errors of the bisection method do not rely at all upon the function whose zeroes are being
		calculated, but rather solely upon the number of iterations carried out by the process. The number of iterations to calculate
		$g(x) = 0$ to sufficent accuracy is exactly the same number of iterations needed to calculate $f(x) = 0$. \\

		\item The convergence rate of a root finding algorithm is the limit of the ratio of the error in iteration $n$ to the error in
		iteration $n-1$ as $n \rightarrow \infty$.
		$$conv = \lim_{n\to\infty} \frac{e_n}{e_{n-1}}$$

		\begin{enumerate}[(i)]

			\item This algorithm is linearlly convergent, or has a constant convergance rate, as the ratio between every adjacent
			error is $\frac{1}{2}$.

			\item This algorithm is quadratically convergent. It is clear that the ratio of $e_n$ to $e_{n-1}$ is cut in half
			after every iteration, making the rate of convergance not a constant factor, but a result of which iteration is
			currently taking place.
			$$(\frac{e_n}{e_{n-1}} = \frac{1}{2^n})|_{n=1}^{\infty}$$ \\

		\end{enumerate}

		\item

	\end{enumerate}

\end{enumerate}

\end{document}


